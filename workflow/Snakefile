from os.path import join
from glob import glob
import datetime
import pandas as pd


##### check snakemake min version #####

from snakemake.utils import min_version

min_version("6.0.5")


##### load config and sample sheets #####


configfile: "config/config.yaml"
configfile: "config/featuresConfig38.json"


def getWrapper(wrapper):
    return "file://%s/%s/wrapper.py" % (
        config["global_files"]["wrapper_directory"],
        wrapper,
    )


# TODO implement validation
# validate(config, schema="../schemas/config.schema.yaml")

##### include files #####


# Workflow features
include: "rules/features.smk"
# Workflow variants
include: "rules/variants.smk"
# Workflow annotate
include: "rules/annotate.smk"
# Workflow training
include: "rules/training.smk"
# Workflow evaluation
include: "rules/evaluation.smk"
# Workflow scores
include: "rules/scores.smk"


# Workflow predict

# Workflow replace

# old rules


include: "rules/process/getUtils.smk"
include: "rules/process/createModelData.smk"


##### all rules #####
def getAllVariantsInput():
    output = []
    for variant_set in config["variants"]:
        output += getVariantsInput(variant_set, "annotate")
    return output


rule all:
    input:
        getAllVariantsInput(),
        vcf=expand(
            "results/features/feature_sets/{feature_set}.vcf.gz",
            feature_set=list(config["feature_sets"].keys()),
        ),
        idx=expand(
            "results/features/feature_sets/{feature_set}.vcf.gz.tbi",
            feature_set=list(config["feature_sets"].keys()),
        ),


# workflow features
# TODO replace hg38 with both genome builds but add hg19 features before in config
rule all_feature_average:
    input:
        expand(
            "results/features/single_vcf/{feature}/hg38/single/{feature}.avg.tsv.gz",
            feature=features.keys(),
        ),


rule all_feature_sets:
    input:
        vcf=expand(
            "results/features/feature_sets/{feature_set}.vcf.gz",
            feature_set=list(config["feature_sets"].keys()),
        ),
        idx=expand(
            "results/features/feature_sets/{feature_set}.vcf.gz.tbi",
            feature_set=list(config["feature_sets"].keys()),
        ),


# Workflow variants
rule all_variants:
    input:
        getAllVariantsInput(),


# Workflow annotate
def getAllAnnotations():
    output = []
    for training in config["training"].values():
        output += [
            "results/annotation/%s/%s.%s.sorted.tsv.gz"
            % (
                training["positives"],
                training["positives"],
                training["feature_set"],
            )
        ]
        output += [
            "results/annotation/%s/%s.%s.sorted.tsv.gz"
            % (
                training["negatives"],
                training["negatives"],
                training["feature_set"],
            )
        ]
    return output


rule all_annotation:
    input:
        getAllAnnotations(),


# Workflow evaluate
rule all_evaluate:
    input:
        expand(
            "results/evaluation/{training_run}/metrics/auc.tsv.gz",
            training_run=list(config["training"].keys()),
        ),


# Workflow variants
rule all_scores:
    input:
        expand(
            "results/scores/{score_name}/release/{score_name}.unbiased.tsv.gz{idx}",
            score_name=list(config["scores"].keys()),
            idx=["", ".tbi"],
        ),
