from os.path import join
from glob import glob
import datetime
import pandas as pd


##### check snakemake min version #####

from snakemake.utils import min_version

min_version("6.0.5")


##### load config and sample sheets #####


configfile: "config/config.yaml"
configfile: "config/featuresConfig38.json"


def getWrapper(wrapper):
    return "file:%s/%s/wrapper.py" % (
        config["global_files"]["wrapper_directory"],
        wrapper,
    )


# TODO implement validation
# validate(config, schema="../schemas/config.schema.yaml")

##### include files #####


# Workflow features
include: "rules/features.smk"
# Workflow variants
include: "rules/variants.smk"
# Workflow annotate
include: "rules/annotate.smk"
# Workflow training
include: "rules/training.smk"
# Workflow evaluation
include: "rules/evaluation.smk"
# Workflow scores
include: "rules/scores.smk"


# Workflow predict

# Workflow replace

# old rules


include: "rules/process/getUtils.smk"
include: "rules/process/createModelData.smk"


##### all rules #####
def getAllVariantsInput():
    output = []
    for variant_set in config["variants"]:
        output += getVariantsInput(variant_set, "annotate")
    return output

def getAllFeatures(genomeBuild):
    featureList = []
    for feature,build in features.items():
        if genomeBuild in build:
            featureList += [feature]
    return(expand(
            "results/features/single_vcf/{feature}/{genomeBuild}/single/{feature}.avg.tsv.gz",
            feature=featureList,
            genomeBuild=genomeBuild,
        ))


rule all:
    input:
        getAllVariantsInput(),
        vcf=expand(
            "results/features/feature_sets/{feature_set}.vcf.gz",
            feature_set=list(config["feature_sets"].keys()),
        ),
        idx=expand(
            "results/features/feature_sets/{feature_set}.vcf.gz.tbi",
            feature_set=list(config["feature_sets"].keys()),
        ),


# workflow features
rule all_feature_average:
    input:
        getAllFeatures("hg19"),
        getAllFeatures("hg38")


rule all_feature_sets:
    input:
        vcf=expand(
            "results/features/feature_sets/{feature_set}.vcf.gz",
            feature_set=list(config["feature_sets"].keys()),
        ),
        idx=expand(
            "results/features/feature_sets/{feature_set}.vcf.gz.tbi",
            feature_set=list(config["feature_sets"].keys()),
        ),


# Workflow variants
rule all_variants:
    input:
        getAllVariantsInput(),


# Workflow annotate
def getAllAnnotations():
    output = []
    for training in config["training"].values():
        output += [
            "results/annotation/%s/%s.%s.sorted.tsv.gz"
            % (
                training["positives"],
                training["positives"],
                training["feature_set"],
            )
        ]
        output += [
            "results/annotation/%s/%s.%s.sorted.tsv.gz"
            % (
                training["negatives"],
                training["negatives"],
                training["feature_set"],
            )
        ]
    return output


rule all_annotation:
    input:
        getAllAnnotations(),


# Workflow evaluate
rule all_evaluate:
    input:
        expand(
            "results/evaluation/{training_run}/metrics/auc.tsv.gz",
            training_run=list(config["training"].keys()),
        ),
        expand(
            "results/evaluation/{training_run}/metrics/curves_prc_roc.png",
            training_run=list(config["training"].keys()),
        ),


# Workflow variants
rule all_scores:
    input:
        expand(
            "results/scores/{score_name}/release/{score_name}.unbiased.tsv.gz{idx}",
            score_name=list(config["scores"].keys()),
            idx=["", ".tbi"],
        ),
