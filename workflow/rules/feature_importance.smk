##########################################
#### feature importance sub workflow  ####
##########################################


"""
Results will be saved in results/training/<training_run>/feature_importance

Reads the feature importance files for each tree, generated by parSMURF.
Replaces features with headers and generates average importance scores.
"""


# add a header to the featuire importance files (required before merging)
rule featureImportance_header:
    input:
        "results/training/{training}/predictions/models/{model_number}.out.importance",
    output:
        temp(
            "results/training/{training}/feature_importance/single/{model_number}.importance.tsv.gz"
        ),
    params:
        model_number=lambda wc: wc.model_number,
    shell:
        """
        (
            echo -e "Feature\\tImportance_{params.model_number}";
            cat {input} | sed 's/\:\s/\\t/g';
        ) | gzip -c > {output}
        """


# concat all model importance scores
rule featureImportance_concat:
    input:
        expand(
            "results/training/{{training}}/feature_importance/single/{model_number}.importance.tsv.gz",
            model_number=list(range(0, 100)),
        ),
    output:
        "results/training/{training}/feature_importance/feature_importance.tsv.gz",
    params:
        index="Feature",
    wrapper:
        getWrapper("file_manipulation/concat")


# replace the feature number defined by parSMURF with the name of the feature
rule featureImportance_replace:
    input:
        "results/training/{training}/feature_importance/feature_importance.tsv.gz",
    output:
        "results/training/{training}/feature_importance/feature_importance.names.tsv.gz",
    params:
        columns=lambda wc: [
            "Feature" for i in range(len(getFeaturesOfTraining(wc.training)))
        ],
        pat=lambda wc: [
            "%d" % i for i in range(len(getFeaturesOfTraining(wc.training)))
        ],
        replace=lambda wc: getFeaturesOfTraining(wc.training),
    wrapper:
        getWrapper("file_manipulation/replace")


# compute the mean max and min for each feature importance
rule featureImportance_aucRepetitiveMean:
    input:
        "results/training/{training}/feature_importance/feature_importance.names.tsv.gz",
    output:
        "results/training/{training}/feature_importance/feature_importance.names.mean_std_min_max.tsv.gz",
    params:
        columns=lambda wc: ["Importance_%d" % num for num in range(100)],
        new_columns=["mean", "std", "min", "max"],
        operations=["mean", "std", "min", "max"],
    wrapper:
        getWrapper("file_manipulation/summarize_columns")
