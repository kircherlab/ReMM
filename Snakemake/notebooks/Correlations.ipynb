{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### liftover hg19 to hg38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPLIFTEN\n",
    "# get the variant positions\n",
    "zcat output/features/annotated/hg19/SNVs.hg19.combined.txt.gz | cut -f 2-3 |  gzip -c > output/predictions/lifted/up/hg19.positions.txt.gz\n",
    "\n",
    "# Add ReMM score to the positions; \n",
    "# ReMM is 1-based, positions also, since stem from VCF annotated files\n",
    "awk 'BEGIN{ OFS=\"\\t\"} NR==FNR{ a[$1 FS $2];next} (\"chr\"$1 FS $2) in a {print \"chr\"$1, $2, $3} ' <(zcat output/predictions/lifted/up/hg19.positions.txt.gz) <(zcat input/variants/hg19/ReMM.v0.3.1.tsv.gz) |gzip -c  > output/predictions/lifted/up/hg19.positions.remm.txt.gz\n",
    "\n",
    "# lifover requires a bed file so -1\n",
    "zcat  output/predictions/lifted/up/hg19.positions.remm.txt.gz  | awk 'BEGIN{ OFS=\"\\t\"}{ print $1,$2-1,$2,$1\":\"$2-1\":\"$3 }' | gzip -c > output/predictions/lifted/up/hg19.positions.remm.bed.gz\n",
    "\n",
    "# liftover\n",
    "liftOver output/predictions/lifted/up/hg19.positions.remm.bed.gz input/variants/hg38/hg19ToHg38.over.chain.gz >( gzip -c > output/predictions/lifted/up/hg19.positions.remm.lifted.bed.gz ) >( gzip -c > output/predictions/lifted/up/failed.bed.gz)\n",
    "\n",
    "# after liftover add 1 to start position\n",
    "zcat  output/predictions/lifted/up/hg19.positions.remm.lifted.bed.gz | awk 'BEGIN{ OFS=\"\\t\"}{ print $1,$2+1,$4}' | gzip -c > output/predictions/lifted/up/hg19.positions.remm.lifted.txt.gz\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>19</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.704102</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          19        38\n",
       "19  1.000000  0.704102\n",
       "38  0.704102  1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# read in the ReMMM scores for hg19 variants (from forder up, since same as thre)\n",
    "file = 'output/predictions/lifted/up/hg19.positions.remm.txt.gz'\n",
    "_df19 = pd.read_csv(file,sep='\\t',header = None)\n",
    "\n",
    "# read i the lifted hg38 variants \n",
    "file = 'output/predictions/lifted/_down/hg38.predictions.lifted.txt.gz'\n",
    "_df38 = pd.read_csv(file,sep='\\t',header = None)\n",
    "\n",
    "# create index column\n",
    "_df38[3]=_df38[0].astype(str)+'-'+_df38[1].astype(str)\n",
    "_df19[3]=_df19[0].astype(str)+'-'+_df19[1].astype(str)\n",
    "\n",
    "# set index to join on \n",
    "_df38 = _df38.set_index(_df38[3])\n",
    "_df19 = _df19.set_index(_df19[3])\n",
    "\n",
    "# inner join the data frames on index\n",
    "_f = _df38.join(_df19,lsuffix='pos',rsuffix='up',how='inner')\n",
    "\n",
    "# create a df with two columns: ReMM scores and parSMURF predictions\n",
    "_df= pd.DataFrame()\n",
    "_df['38'] = _f['2pos'].str.split(':',expand = True)[2]\n",
    "_df['19']= _f['2up']\n",
    "\n",
    "# calculate correlations\n",
    "_df[['19','38']].astype(float).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = _df38.drop_duplicates([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13878373, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df38.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13856298, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c09256a3aae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_df38\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/miniconda/envs/jupyter/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   5244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5245\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5246\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5248\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_group_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxnull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/miniconda/envs/jupyter/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(vals)\u001b[0m\n\u001b[1;32m   5218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5219\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5220\u001b[0;31m             labels, shape = algorithms.factorize(\n\u001b[0m\u001b[1;32m   5221\u001b[0m                 \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SIZE_HINT_LIMIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5222\u001b[0m             )\n",
      "\u001b[0;32m~/work/miniconda/envs/jupyter/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0mna_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         codes, uniques = _factorize_array(\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n",
      "\u001b[0;32m~/work/miniconda/envs/jupyter/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_factorize_array\u001b[0;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m     uniques, codes = table.factorize(\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     )\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.StringHashTable.factorize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.StringHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/work/miniconda/envs/jupyter/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"Convert the input to an array.\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_df38.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-22075"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13856298 -13878373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12881484, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### liftover  hg38 to hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOWNLIFTEN\n",
    "#get the variant positions + predictions\n",
    "paste  -d \"\\t\"  <(zcat output/features/annotated/hg38/SNVs.hg38.combined.txt.gz | cut -f 2-3) output/predictions/hg38/SNVs.hg38.predictions.txt | awk 'BEGIN{ OFS=\"\\t\" }{ print $1,$2,$3}' | gzip -c > output/predictions/lifted/_down/hg38.predictions.txt.gz\n",
    "\n",
    "# lifover requires a bed file so -1\n",
    "zcat  output/predictions/lifted/_down/hg38.predictions.txt.gz  | awk 'BEGIN{ OFS=\"\\t\"}{ print $1,$2-1,$2,$1\":\"$2-1\":\"$3 }' | gzip -c > output/predictions/lifted/_down/hg38.positions.bed.gz\n",
    "\n",
    "# liftover\n",
    "liftOver output/predictions/lifted/_down/hg38.positions.bed.gz input/variants/hg19/hg38ToHg19.over.chain.gz >( gzip -c > output/predictions/lifted/_down/hg38.predictions.lifted.bed.gz ) >( gzip -c > output/predictions/lifted/_down/failed.bed.gz)\n",
    "\n",
    "# after liftover add 1 to start position\n",
    "zcat  output/predictions/lifted/_down/hg38.predictions.lifted.bed.gz | awk 'BEGIN{ OFS=\"\\t\"}{ print $1,$2+1,$4}' | gzip -c > output/predictions/lifted/_down/hg38.predictions.lifted.txt.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  read in lifted ReMM scores\n",
    "file = 'output/predictions/lifted/up/hg19.positions.remm.lifted.txt.gz'\n",
    "df19 = pd.read_csv(file,sep='\\t',header = None)\n",
    "\n",
    "# read in parSMURF predictions\n",
    "file = 'output/predictions/lifted/up/hg38.pred.txt.gz'\n",
    "df38 = pd.read_csv(file,sep='\\t',header = None)\n",
    "\n",
    "\n",
    "\n",
    "df19[2] = df19[2].str.split(':',expand = True)[2]\n",
    "\n",
    "df38[3]=df38[0].astype(str)+'-'+df38[1].astype(str)\n",
    "df19[3]=df19[0].astype(str)+'-'+df19[1].astype(str)\n",
    "\n",
    "df38 = df38.set_index(df38[3])\n",
    "df19 = df19.set_index(df19[3])\n",
    "\n",
    "f = df38.join(df19,lsuffix='pos',rsuffix='up',how='inner')\n",
    "\n",
    "df= pd.DataFrame()\n",
    "df['38'] = f['2pos']\n",
    "df['19']= f['2up']#.str.split(':',expand = True)[2]\n",
    "\n",
    "\n",
    "df[['19','38']].astype(float).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hg19 and hg38 calculated with parSMURF (w/o ReMM): liftover hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste  -d \"\\t\"  <(zcat output/features/annotated/hg19/SNVs.hg19.combined.txt.gz | cut -f 2-3) output/predictions/hg19/SNVs.hg19.predictions.txt | awk 'BEGIN{ OFS=\"\\t\" }{ print $1,$2,$3}' | gzip -c > output/predictions/lifted/_up/hg19.predictions.txt.gz\n",
    "\n",
    "zcat  output/predictions/lifted/_up/hg19.predictions.txt.gz  | awk 'BEGIN{ OFS=\"\\t\"}{ print $1,$2-1,$2,$1\":\"$2-1\":\"$3 }' | gzip -c > output/predictions/lifted/_up/hg19.predictions.bed.gz\n",
    "\n",
    "liftOver output/predictions/lifted/_up/hg19.predictions.bed.gz input/variants/hg38/hg19ToHg38.over.chain.gz >( gzip -c > output/predictions/lifted/_up/hg19.predictions.lifted.bed.gz ) >( gzip -c > output/predictions/lifted/_up/hg19.falied.bed.gz)\n",
    "\n",
    "zcat  output/predictions/lifted/_up/hg19.predictions.lifted.bed.gz | awk 'BEGIN{ OFS=\"\\t\"}{ print $1,$2+1,$4}' | gzip -c > output/predictions/lifted/_up/hg19.predictions.lifted.txt.gz\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in lifted parSMURF predictions for hg19\n",
    "file = 'output/predictions/lifted/_up/hg19.predictions.lifted.txt.gz'\n",
    "df19_0 = pd.read_csv(file,sep='\\t',header = None)\n",
    "\n",
    "# read in  parSMURF predictions for hg38\n",
    "\n",
    "file = 'output/predictions/lifted/_up/hg38.predictions.txt.gz'\n",
    "df38_0 = pd.read_csv(file,sep='\\t',header = None)\n",
    "\n",
    "\n",
    "df19_0[2] = df19_0[2].str.split(':',expand = True)[2]\n",
    "\n",
    "df38_0[3]=df38_0[0].astype(str)+'-'+df38_0[1].astype(str)\n",
    "df19_0[3]=df19_0[0].astype(str)+'-'+df19_0[1].astype(str)\n",
    "\n",
    "df38_0 = df38_0.set_index(df38_0[3])\n",
    "df19_0 = df19_0.set_index(df19_0[3])\n",
    "\n",
    "f_0 = df38_0.join(df19_0,lsuffix='pos',rsuffix='up',how='inner')\n",
    "\n",
    "df_0= pd.DataFrame()\n",
    "df_0['38'] = f_0['2pos']\n",
    "df_0['19']= f_0['2up']#.str.split(':',expand = True)[2]\n",
    "\n",
    "\n",
    "df_0[['19','38']].astype(float).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hg19 and hg38 calculated with parSMURF (w/o ReMM): liftover hg38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste  -d \"\\t\"  <(zcat output/features/annotated/hg38/SNVs.hg38.combined.txt.gz | cut -f 2-3) output/predictions/hg38/SNVs.hg38.predictions.txt | awk 'BEGIN{ OFS=\"\\t\" }{ print $1,$2,$3}' | gzip -c > output/predictions/lifted/_up/hg38.predictions.txt.gz\n",
    "\n",
    "zcat  output/predictions/lifted/_up/hg38.predictions.txt.gz  | awk 'BEGIN{ OFS=\"\\t\"}{ print $1,$2-1,$2,$1\":\"$2-1\":\"$3 }' | gzip -c > output/predictions/lifted/_up/hg38.predictions.bed.gz\n",
    "\n",
    "liftOver output/predictions/lifted/_up/hg38.predictions.bed.gz input/variants/hg19/hg38ToHg19.over.chain.gz >( gzip -c > output/predictions/lifted/_up/hg38.predictions.lifted.bed.gz ) >( gzip -c > output/predictions/lifted/_up/hg38.falied.bed.gz)\n",
    "\n",
    "zcat  output/predictions/lifted/_up/hg38.predictions.lifted.bed.gz | awk 'BEGIN{ OFS=\"\\t\"}{ print $1,$2+1,$4}' | gzip -c > output/predictions/lifted/_up/hg38.predictions.lifted.txt.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in lifted parSMURF predictions for hg38\n",
    "\n",
    "file = 'output/predictions/lifted/_up/hg38.predictions.lifted.txt.gz'\n",
    "df19_1 = pd.read_csv(file,sep='\\t',header = None)\n",
    "\n",
    "# read in parSMURF predictions for hg19\n",
    "\n",
    "file = 'output/predictions/lifted/_up/hg19.predictions.txt.gz'\n",
    "df38_1 = pd.read_csv(file,sep='\\t',header = None)\n",
    "\n",
    "\n",
    "df19_1[2] = df19_1[2].str.split(':',expand = True)[2]\n",
    "\n",
    "df38_1[3]=df38_1[0].astype(str)+'-'+df38_1[1].astype(str)\n",
    "df19_1[3]=df19_1[0].astype(str)+'-'+df19_1[1].astype(str)\n",
    "\n",
    "df38_1 = df38_1.set_index(df38_1[3])\n",
    "df19_1 = df19_1.set_index(df19_1[3])\n",
    "\n",
    "f = df38_1.join(df19_1,lsuffix='pos',rsuffix='up',how='inner')\n",
    "\n",
    "df_1= pd.DataFrame()\n",
    "df_1['38'] = f_1['2pos']\n",
    "df_1['19']= f_1['2up']#.str.split(':',expand = True)[2]\n",
    "\n",
    "\n",
    "df_1[['19','38']].astype(float).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### liftover hg38 to hg19 but bash join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "join -j 1 <(zcat output/predictions/lifted/down/hg38.predictions.lifted.bed.gz | sort -k1,1 -k2,2n -k3,3n | awk 'BEGIN{ OFS=\"\\t\"} {split($0,a,\":\"); printf(\"%s:%015d\\t%s\\t%s\\t%s\\n\",$1,$3,$1,$2,a[3]) }' ) <(zcat input/variants/hg19/ReMM.v0.3.1.tsv.gz | tail -n +3 | awk 'BEGIN{ OFS=\"\\t\"}{ printf(\"chr%s:%015d\\t%s\\n\",$1,$2,$3) }') | gzip -c > output/predictions/lifted/down/joined_kor.txt.gz\n",
    "\n",
    "\n",
    "zcat  output/predictions/lifted/down/joined_kor.txt.gz | awk 'BEGIN{ OFS=\"\\t\"}{ print $5,$6}' | gzip -c > output/predictions/lifted/down/joined_korr.txt.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'output/predictions/lifted/down/joined_kor.txt.gz'\n",
    "df0 = pd.read_csv(file,sep=' ',header = None, usecols  =[3,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035974</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021006</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062250</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510135</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4\n",
       "0  0.035974  0.018\n",
       "1  0.021006  0.178\n",
       "2  0.062250  0.012\n",
       "3  0.510135  0.166\n",
       "4  0.000386  0.016"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.690586</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          3         4\n",
       "3  1.000000  0.690586\n",
       "4  0.690586  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
