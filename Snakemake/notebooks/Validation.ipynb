{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pybedtools as bt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pybedtools as bt\n",
    "import pyBigWig as bw\n",
    "import os\n",
    "pd.options.display.max_rows = 10000\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('/fast/work/groups/ag_kircher/ReMM/MA_Lusi/Snakemake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snakemake -n output/predictions/hg38/SNVs.hg38.predictions.txt_{79831,29779,19259,15152,96584,26373,56705,70836,63553,80755,78121,22797,92565,14842,54865,19484,88549,33145,39400,64327,49468,21150,30844,38251,93902,79273,95330,20673,53504,54216,66408,78518,54871,93623,37164,98729,18102,43164,77581,83137,85174,57134,84389,88901,61887,19171,61435,91673,30544,20311}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "'snakemake -n output/predictions/hg38/SNVs.hg38.predictions.txt_'+str(random.sample(range(10000, 99999), 50)).replace(' ','').replace('[','{').replace(']','}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getData(r):\n",
    "    di = {'chr5':'PRDM9','chr11':'HBB','chr14':'DLK1'}\n",
    "\n",
    "    to_replace = {'priPhCons':'priPhastCons',\n",
    "        'mamPhCons':'mamPhastCons',\n",
    "        'verPhCons':'verPhastCons',\n",
    "        'priPhyloP':'priPhyloP',\n",
    "        'mamPhyloP':'mamPhyloP',\n",
    "        'verPhyloP':'verPhyloP',\n",
    "        'EncodeH3K4me1-max'   :'EncH3K4Me1',\n",
    "        'EncodeH3K4me3-max': 'EncH3K4Me3',\n",
    "        'EncodeH3K27ac-max' :   'EncH3K27Ac',\n",
    "        'Pos':'POSITION',\n",
    "        'GerpRS': 'GerpRS',\n",
    "         'GerpRSpval':'GerpRSpv',\n",
    "        'EncOCDNaseSig':'DnaseClusteredScore',\n",
    "         'EncodeDNase-max':'DnaseClusteredScore',\n",
    "        'EncodeDNase-sum':'DnaseClusteredHyp',\n",
    "        'EncOCDNasePVal':'DnaseClusteredHyp',\n",
    "                 'GC':'GCContent',\n",
    "                 'CpG':'CpGperCpG',\n",
    "                 'GCContent':'GCContent',\n",
    "                 'CpGperCpG':'CpGperCpG'}\n",
    "\n",
    "\n",
    "    for chrom in list(di.keys())[0:1]:\n",
    "        chrom = r\n",
    "        c = di[chrom]\n",
    "        #print(chrom)\n",
    "        cadd19_ = pd.read_csv('/data/groups/ag_kircher/ReMM/MA_Lusi/CADD_feature_comparison/'+c+'_hg19.tsv.gz',sep = '\\t') \n",
    "        cadd38_ = pd.read_csv('/data/groups/ag_kircher/ReMM/MA_Lusi/CADD_feature_comparison/'+c+'_hg38.tsv.gz',sep = '\\t') \n",
    "\n",
    "\n",
    "        cols = list(pd.Series(to_replace).unique())\n",
    "        cadd38_.columns = pd.Series(cadd38_.columns).replace(to_replace)\n",
    "        cadd38 = cadd38_.fillna(0).loc[:,cols]\n",
    "        cadd19_.columns = pd.Series(cadd19_.columns).replace(to_replace)\n",
    "        cadd19 = cadd19_.fillna(0).loc[:,cols]\n",
    "\n",
    "        cols = hg38.columns.to_list()\n",
    "        df19 = pd.read_csv('validation/'+chrom+'.features19.txt.gz',sep = '\\t')\n",
    "        df19.columns = df19.columns.str.replace('46way','')\n",
    "        df19 = df19.loc[:,cols]\n",
    "        df19 = df19.fillna(0).round(3)\n",
    "\n",
    "        df38 = pd.read_csv('validation/'+chrom+'.features38.txt.gz',sep = '\\t')\n",
    "        df38.columns = df38.columns.str.replace('Fantom','fantom')\n",
    "        df38 = df38.loc[:,cols]\n",
    "        df38 = df38.fillna(0).round(3)\n",
    "\n",
    "       # print(chrom)\n",
    "        modes = ['EncH3K27Ac','EncH3K4Me3','EncH3K4Me1']\n",
    "        modes = ['priPhastCons','priPhyloP','verPhastCons','verPhyloP','mamPhastCons','mamPhyloP']\n",
    "\n",
    "\n",
    "        for mode in modes:\n",
    "         #   print(mode)\n",
    "            #print(pd.DataFrame([cadd19[mode],df19[mode],hg19[mode]]).T.corr())\n",
    "            #print(pd.DataFrame([cadd38[mode],df38[mode],hg38[mode]]).T.corr())\n",
    "\n",
    "        #print(\"19: cadd und df \\n\\n\",cadd19.corrwith(df19))\n",
    "        #print(\"19: cadd und df  \\n\\n\",cadd38.corrwith(df38))\n",
    "        #print(\"19: cadd und hg  \\n\\n\",cadd19.corrwith(hg19))\n",
    "        #print(\"38: cadd und hg  \\n\\n\",cadd38.corrwith(hg38))\n",
    "\n",
    "        #print(cadd19.corrwith(cadd38))ich m\n",
    "        #print(df19.corrwith(df38))\n",
    "        return cadd19,cadd38, df19,df38\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import json\n",
    "\n",
    "\n",
    "#with open('config/features_config.json') as f:\n",
    "#    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Validate:\n",
    "    def __init__(self,b ='hg38',r = 2):\n",
    "    \n",
    "        regions = [{'hg19':['chr5',23464354,23570942],'hg38':['chr5',23464245,23570833]},\n",
    "                    {'hg19':['chr11',5167199,5327798],'hg38':['chr11',5145969,5306568]},\n",
    "                    {'hg19':['chr14',101118632,101242576],'hg38':['chr14',100652295,100776239]},\n",
    "                   {'hg19':['chr14',101118632,201242576],'hg38':['chr14',100652295,200776239]}]\n",
    "        self.di = regions[r]\n",
    "        self.b = b\n",
    "        self.start = self.di[self.b][1]-1\n",
    "        self.end = self.di[self.b][2]\n",
    "        self.chr = self.di[self.b][0]\n",
    "        \n",
    "    def get_bed(self):\n",
    "        \n",
    "        # die Positionen in den Regionen sind 1-basiert (wegen featureVcfHg19)\n",
    "        # eine BED Datei erstellen: Start und Endposition -1\n",
    "\n",
    "        bed = pd.DataFrame()\n",
    "        #print(start,end)\n",
    "        s = self.start \n",
    "        e = self.end \n",
    "        \n",
    "        bed['START'] =  range(s,e)\n",
    "        bed['END'] =  range(s+1,e+1)\n",
    "        bed['CHR'] = self.chr\n",
    "        self.bed = bed[['CHR','START','END']]\n",
    "        return self.bed\n",
    "    \n",
    "    def getEncode(self):\n",
    "        # die Originaldateien für hg19 sind heruntergeladen (Link in der feature_config)\n",
    "        # 1-basiret, die Werte sind mit pyBigWig extrahiert, der Maximum von allen Zelllinien ist berechnet\n",
    "        self.mods = ['EncH3K27Ac','EncH3K4Me3','EncH3K4Me1']\n",
    "        #self.mods = ['EncH3K4Me3']\n",
    "\n",
    "        hg = pd.DataFrame()\n",
    "        for mod in self.mods:\n",
    "            vv = []\n",
    "            files = glob('input/features/'+self.b+'/'+mod+'/*.bigWig')\n",
    "            for file in files:\n",
    "                #print(file)\n",
    "                self.file = file\n",
    "                bb = bw.open(self.file )\n",
    "                v = bb.values(self.di[self.b][0], self.start, self.end) \n",
    "                vv.append(v)\n",
    "            df = pd.DataFrame(vv).T\n",
    "            hg[mod] = df.max(axis = 1)\n",
    "        print(hg.shape)\n",
    "        return hg, df\n",
    "    \n",
    "    \n",
    "    def addID(self,df):\n",
    "        \n",
    "        # eine ID hinzufügen wenn die Featuer Bed sie nicht hat sodass Ausgabe für alle Features gleich ist\n",
    "        df['id'] = df[0]+':'+df[1].astype(str)+':'+df[2].astype(str)\n",
    "        df = df[[0,1,2,'id']+df.columns[3:-1].to_list()]\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def intersect_with_bed(self,featureBed):\n",
    "        \n",
    "        # Features im BED Format werden mit pybedtools extrahiert, dafür wird Intersection zwischen\n",
    "        # der Feature Datei und der BED Dataframe vom getBed berechnet. Beide Dateien werden zuerst zum BedTool konvertiert\n",
    "        # zusätzlich ein paar column name manipualtions \n",
    "        self.featureBed = featureBed\n",
    "        cols = self.featureBed.columns.astype(str)\n",
    "\n",
    "        self.bedTool = bt.BedTool.from_dataframe(self.get_bed())\n",
    "        self.featureBed = bt.BedTool.from_dataframe(self.featureBed)\n",
    "        featureIntersect = self.bedTool.intersect(self.featureBed, loj = True)\n",
    "        self.featureIntersect = featureIntersect.to_dataframe(disable_auto_names=True,names=cols)\n",
    "        \n",
    "        self.featureIntersect.index.names =['chr','start','end']\n",
    "        self.featureIntersect = self.featureIntersect.reset_index()\n",
    "        #c = pd.Series(self.featureIntersect.columns)\n",
    "        #self.featureIntersect.columns = pd.to_numeric(c, errors='coerce').fillna(c)\n",
    "        \n",
    "        return self.featureIntersect.replace(-1,np.nan)\n",
    "    \n",
    "    def get_fantom(self):\n",
    "         \n",
    "        # getFantom gibt eine DF mit Duplikaten zurück.\n",
    "        # habe sie erstmal gedropped\n",
    "        perm = pd.read_csv('input/features/'+self.b+'/Fantom5Perm/Fantom5Perm.all.bed.gz',sep = '\\t', header = None,usecols= [0,1,2,3,4])\n",
    "        robust = pd.read_csv('input/features/'+self.b+'/Fantom5Robust/Fantom5Robust.all.bed.gz',sep = '\\t', header = None,usecols= [0,1,2,3,4])\n",
    "        \n",
    "        \n",
    "        self.perm_df = self.intersect_with_bed(perm)\n",
    "        self.robust_df = self.intersect_with_bed(robust)\n",
    "        \n",
    "        self.perm_df = self.perm_df.groupby('start')['4'].mean().reset_index(drop=True)\n",
    "        self.robust_df = self.robust_df.groupby('start')['4'].mean().reset_index(drop=True)\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        df['fantom5Perm'] = self.perm_df#['4']\n",
    "        df['fantom5Robust']= self.robust_df#['4']\n",
    "        \n",
    "        return df.replace(-1,np.nan)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    def getDnase(self):\n",
    "        \n",
    "        # Dnase Dateien sind auch im BED Format\n",
    "        dnase = pd.read_csv('input/features/'+self.b+'/DnaseClusteredHyp/DnaseClusteredHyp.all.bed.gz', sep = '\\t', header = None,usecols = [0,1,2,3,4])\n",
    "        self.dnase_df = self.addID(dnase)\n",
    "\n",
    "        self.dnase_df = self.intersect_with_bed(self.dnase_df)\n",
    "        \n",
    "        \n",
    "        return self.dnase_df.iloc[:,-2:].apply(lambda x: x.str.replace('.','0')).astype(float)\n",
    "    \n",
    "    def get_conservation(self):\n",
    "        \n",
    "        # für hg19 sind die conservation scores für die 3 Chromosome heruntergeladen\n",
    "        # Dateien für beide Builds sind von wigFix to BigWig convertiert\n",
    "        # 1-basiert\n",
    "        hg = pd.DataFrame()\n",
    "        self.consScores = ['priPhastCons','priPhyloP','verPhastCons','verPhyloP','mamPhastCons','mamPhyloP']\n",
    "        for score in self.consScores:\n",
    "           # print(score)\n",
    "            if ('pri' in score) and (self.b=='hg38'):\n",
    "                st = 'input/features/validation/hg38/'+score+'/'+'*.bw'\n",
    "                #print(st)\n",
    "\n",
    "                file = glob(st)\n",
    "            else: \n",
    "                st = 'input/features/validation/hg38/'+score+'/'+self.di[self.b][0]+'*.bw'\n",
    "                file = glob(st) #chr11_phastCons100way.bw\n",
    "                #print(st)\n",
    "\n",
    "            if self.b=='hg19':\n",
    "                st = 'input/features/hg19/'+score+'/'+self.di[self.b][0]+'_'+'*.bw'\n",
    "                #print(st)\n",
    "\n",
    "                file = glob(st)\n",
    "            if len(file)>1:\n",
    "                print('More than one BW!')\n",
    "                print(file)\n",
    "            bb = bw.open(file[0])\n",
    "            v = bb.values(self.chr, self.start, self.end) \n",
    "            hg[score] = v\n",
    "        #print(hg.shape)\n",
    "        return hg\n",
    "    \n",
    "    def getGCIslands(self):\n",
    "        \n",
    "        gc = pd.read_csv('input/features/'+self.b+'/cpgIslandExt/cpgIslandExt.all.bed.gz', sep = '\\t', header = None,usecols =[0,1,2,7,8,9])\n",
    "        self.gc = self.addID(gc)\n",
    "        #print(self.gc.head())\n",
    "        self.gc_df = self.intersect_with_bed(self.gc)[['7','8','9']]\n",
    "        #print(self.gc_df.head())\n",
    "\n",
    "        self.gc_df.columns = self.gc_df.columns.astype(int)\n",
    "        return self.gc_df[[7,8,9]].apply(lambda x: x.str.replace('.','0')).astype(float)\n",
    "    \n",
    "    def getCGContent(self):\n",
    "        gc =bt.BedTool('input/features/hg38/GCContent/GCContent.all.bed.gz')\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getGerpRS(self):\n",
    "        # assume that Gerp is 0-based/ no info in description on the webpage\n",
    "        gerp = pd.read_csv('input/features/'+self.b+'/GerpRS/GerpRS.all.bed.gz', sep='\\t', header = None)\n",
    "        self.gerp_df = self.addID(gerp)\n",
    "        self.gerp_df = self.intersect_with_bed(self.gerp_df)\n",
    "        return self.gerp_df.iloc[:,-2:].apply(lambda x: x.str.replace('.','0')).astype(float)\n",
    "\n",
    "    def getSTVar(self,feature, file):    \n",
    "        #print('input/features/'+self.b+'/'+feature+'/'+file +'.bed.gz')\n",
    "        self.stv = pd.read_csv('input/features/'+self.b+'/'+feature+'/'+file +'.bed.gz',sep = '\\t',header= None,usecols = [0,1,2,3])\n",
    "        self.stv_df = self.addID(self.stv )\n",
    "        self.stv_df = self.intersect_with_bed(self.stv_df)\n",
    "        #display(self.stv_df)\n",
    "        return self.stv_df['3']\n",
    "    \n",
    "    def getDGVCount(self,):\n",
    "        alle = pd.DataFrame()\n",
    "        st ='input/features/'+self.b+'/DGVCount/DGVCount.'+self.chr+'.bed.gz'\n",
    "        file = glob(st)\n",
    "        #print(st)\n",
    "        dgv = pd.read_csv(file[0],compression='gzip',sep = '\\t',header = None)\n",
    "        self.dgv = dgv.sort_values(dgv.columns.to_list())[[0,1,2,3]]\n",
    "\n",
    "        self.dgv_df = self.addID(self.dgv)\n",
    "        self.dgv_df = self.intersect_with_bed(self.dgv_df)\n",
    "        \n",
    "        return self.dgv_df['3']\n",
    "        \n",
    "    def getAllSTVar(self):\n",
    "        \n",
    "        fdi={'ISCApath':'ISCApath.nstd37_nstd45_nstd75','dbVARCount':'dbVARCount.all'}\n",
    "        #fdi={'DGVCount':'DGVCount.all'}\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for feature in fdi.keys():\n",
    "            #print(feature)\n",
    "            file = fdi[feature]\n",
    "            df[feature]=self.getSTVar(feature,file)\n",
    "        return df[fdi.keys()]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getAll(self):\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        df['POSITION'] = range(self.di[self.b][1],self.di[self.b][2]+1)\n",
    "        df[self.mods] = self.getEncode()[0]\n",
    "        df[['fantom5Perm','fantom5Robust']] = self.get_fantom()\n",
    "        df[self.consScores] = self.get_conservation()\n",
    "        df[['DnaseClusteredHyp','DnaseClusteredScore']]=self.getDnase()\n",
    "        df[['CpGperCpG','CpGperGC','CpGobsExp']] = self.getGCIslands()\n",
    "        df[['GerpRS','GerpRSpv']] = self.getGerpRS()\n",
    "        df[['ISCApath','dbVARCount']] = self.getAllSTVar()\n",
    "        df[['DGVCount']] = self.getDGVCount()\n",
    "\n",
    "        \n",
    "        \n",
    "        return df.fillna(0).astype(float).round(3)\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### All the features are comment 'out' except for variants/ to change - comment 'in' in functions (last lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106589, 3)\n",
      "priPhastCons\n",
      "priPhyloP\n",
      "verPhastCons\n",
      "verPhyloP\n",
      "mamPhastCons\n",
      "mamPhyloP\n",
      "----------------\n",
      "(106589, 3)\n",
      "priPhastCons\n",
      "priPhyloP\n",
      "verPhastCons\n",
      "verPhyloP\n",
      "mamPhastCons\n",
      "mamPhyloP\n",
      "(160600, 3)\n",
      "priPhastCons\n",
      "priPhyloP\n",
      "verPhastCons\n",
      "verPhyloP\n",
      "mamPhastCons\n",
      "mamPhyloP\n",
      "----------------\n",
      "(160600, 3)\n",
      "priPhastCons\n",
      "priPhyloP\n",
      "verPhastCons\n",
      "verPhyloP\n",
      "mamPhastCons\n",
      "mamPhyloP\n",
      "(123945, 3)\n",
      "priPhastCons\n",
      "priPhyloP\n",
      "verPhastCons\n",
      "verPhyloP\n",
      "mamPhastCons\n",
      "mamPhyloP\n",
      "----------------\n",
      "(123945, 3)\n",
      "priPhastCons\n",
      "priPhyloP\n",
      "verPhastCons\n",
      "verPhyloP\n",
      "mamPhastCons\n",
      "mamPhyloP\n"
     ]
    }
   ],
   "source": [
    "# r is one of the intervals (0,1,2)\n",
    "df = pd.DataFrame()\n",
    "df['col']=col\n",
    "df = df.set_index('col')\n",
    "for r in [0,1,2]:\n",
    "   \n",
    "    x38 = Validate(b = 'hg38', r=r)\n",
    "    hg38 = x38.getAll()\n",
    "    print('----------------')\n",
    "    x19 = Validate(b = 'hg19',r=r)\n",
    "    hg19 = x19.getAll()\n",
    "    d = hg19.corrwith(hg38)\n",
    "    d.name = r\n",
    "    df = df.join(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identical regions + Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DLK1</th>\n",
       "      <td>106589.0</td>\n",
       "      <td>0.575921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HBB</th>\n",
       "      <td>160600.0</td>\n",
       "      <td>0.664163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRDM9</th>\n",
       "      <td>123945.0</td>\n",
       "      <td>0.639591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>119533.0</td>\n",
       "      <td>0.602342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1\n",
       "DLK1    106589.0  0.575921\n",
       "HBB     160600.0  0.664163\n",
       "PRDM9   123945.0  0.639591\n",
       "Random  119533.0  0.602342"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = []\n",
    "l = []\n",
    "for c in ['chr5','chr11','chr14']:\n",
    "\n",
    "    d1 = pd.read_csv('output/predictions/'+c+'/SNVs.'+c+'.predictions.txt',sep = '\\t',header = None )[0]\n",
    "    d2 = pd.read_csv('output/predictions/'+c+'/SNVs.'+c+'.remm.txt',sep = '\\t',header = None )[2]\n",
    "    cor.append(pd.DataFrame([d1,d2]).T.corr().iloc[0,1])\n",
    "    l.append(d2.shape[0])\n",
    "    \n",
    "cor.append(0.602342)\n",
    "c = pd.read_csv('output/predictions/random/SNVs.random.predictions.txt',sep= '\\t',header = None).shape[0]\n",
    "c2 = pd.read_csv('output/predictions/random/hg19random.remm.txt.gz',sep= '\\t',header = None)#.shape[0]\n",
    "\n",
    "\n",
    "l.append(c)\n",
    "\n",
    "d = pd.DataFrame([l,cor])\n",
    "d.columns = ['DLK1','HBB','PRDM9','Random']\n",
    "d.index = ['Length','Correlation']\n",
    "#d.to_latex('figures/lc.tex', index = True,header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tree identical regions + radom\n",
    "col = ['CpGperGC', 'CpGperCpG', 'CpGobsExp','GCContent','EncH3K27Ac', 'EncH3K4Me1',\n",
    "       'EncH3K4Me3', 'verPhyloP', 'mamPhyloP',\n",
    "       'priPhyloP','priPhastCons', 'mamPhastCons','verPhastCons', 'DnaseClusteredHyp', 'DnaseClusteredScore', \n",
    "         'Fantom5Perm','Fantom5Robust','GerpRS', 'GerpRSpv', 'rareVar', 'commonVar', 'fracRareCommon',\n",
    "        'numTFBSConserved',\n",
    "       'ISCApath', 'DGVCount', 'dbVARCount']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['col']=col\n",
    "df = df.set_index('col')\n",
    "\n",
    "for c in ['chr5','chr11','chr14']:\n",
    "    d = pd.read_csv('validation/'+c+'.features19.txt.gz',sep = '\\t')\n",
    "    d.columns = d.columns.str.replace('46way','')\n",
    "    d.columns = d.columns.str.replace('fantom','Fantom')\n",
    "\n",
    "    d1 = pd.read_csv('output/features/annotated/'+c+'/SNVs.'+c+'.combined.txt.gz',sep = '\\t')\n",
    "    \n",
    "    j = d.corrwith(d1)\n",
    "    j.name = c\n",
    "    df = df.join(j)\n",
    "    \n",
    "    \n",
    "file = 'output/predictions/random/hg19random.features.vcf.gz'\n",
    "d = pd.read_csv(file,sep = '\\t',skiprows = 0)\n",
    "#d[d[0].str.len()<6].to_csv(file,sep = '\\t',index =False,header = False)\n",
    "#d.head(100)\n",
    "\n",
    "d.columns = d.columns.str.replace('46way','')\n",
    "d.columns = d.columns.str.replace('fantom','Fantom')\n",
    "\n",
    "\n",
    "file = 'output/predictions/random/hg38random.features.vcf.gz'\n",
    "d1 = pd.read_csv(file,sep = '\\t',skiprows = 0)\n",
    "d1['ID']=d1['CHR']+':'+d1['POSITION'].astype(str)\n",
    "\n",
    "d['ID']=d['ID'].str.split(':',expand = True)[0]+':'+d['ID'].str.split(':',expand = True)[1]\n",
    "\n",
    "\n",
    "dd = d.join(d1,lsuffix = '_ReMM',rsuffix='_parSMURF',how = 'inner')\n",
    "\n",
    "\n",
    "d19 = dd.loc[:,dd.columns.str.contains('ReMM')]\n",
    "d19.columns = d19.columns.str.replace('_ReMM','')\n",
    "d38 = dd.loc[:,dd.columns.str.contains('parSMURF')]\n",
    "d38.columns = d38.columns.str.replace('_parSMURF','')\n",
    "\n",
    "\n",
    "d = d.set_index('ID',drop = True)\n",
    "d1= d1.set_index('ID',drop = True) #SNVs.chr5.data.txt\n",
    "\n",
    "\n",
    "d = d19.corrwith(d38)[1:]\n",
    "d.name = 'Random'\n",
    "\n",
    "df = df.join(d)\n",
    "df.columns = ['DLK1','HBB','PRDM9','Random']\n",
    "df.index.name = ''\n",
    "\n",
    "#df.to_latex('figures/identical.tex', index = True,header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSITION      1.000000\n",
       "ISCApath      0.754903\n",
       "dbVARCount    0.946756\n",
       "DGVCount      0.987430\n",
       "dtype: float64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df38.corrwith(hg38)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSITION        1.000000\n",
       "priPhastCons    0.792354\n",
       "priPhyloP       0.728944\n",
       "verPhastCons    0.682659\n",
       "verPhyloP       0.615702\n",
       "mamPhastCons    0.670038\n",
       "mamPhyloP       0.510452\n",
       "DGVCount        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg19.corrwith(hg38)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISCApath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the reason for the correlation equaling NaN\n",
    "df19['ISCApath'].value_counts()\n",
    "#for col in df19.iloc[:,1:]:\n",
    "#    print(df19[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hg19['ISCApath'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg38['ISCApath'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 23464354\n",
    "x = x-1 # the class returns a vcf table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file ='hg19.variants/isca/all_variants_for_nstd75.csv.gz'\n",
    "df = pd.read_csv(file, sep = ',', skiprows=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alle.to_csv('input/features/hg38/ISCApath/ISCApath.nstd37_nstd45_nstd75.bed.gz.vartmp',sep = '\\t', index = False,header = False,compression = 'gzip')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the combination of the original files, is produced by the rule variants.snakerule (not the intervals)\n",
    "file = 'input/features/hg19/ISCApath/ISCApath.nstd37_nstd45_nstd75.bed.gz.vartmp'\n",
    "\n",
    "df0 = pd.read_csv(file,compression='gzip',sep = '\\t',header = None)\n",
    "df0=df0.sort_values([0,1,2,3]).reset_index(drop=True ) \n",
    "\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[~df[3].isin(df0[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the interval file \n",
    "file = 'input/features/hg19/ISCApath/ISCApath.nstd37_nstd45_nstd75.bed.gz'\n",
    "\n",
    "df1 = pd.read_csv(file,compression='gzip',sep = '\\t',header = None)\n",
    "df1=df1.sort_values([0,1,2,3]).reset_index(drop=True ) \n",
    "\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[0]==x19.chr)&(df[1]<=x)&(df[2]>=x)].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0[(df0[0]==x19.chr)&(df0[1]<=x)&(df0[2]>=x)].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[(df1[0]==x19.chr)&(df1[1]<=x)&(df1[2]>=x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48554</th>\n",
       "      <td>chr11</td>\n",
       "      <td>4621644</td>\n",
       "      <td>5179426</td>\n",
       "      <td>nsv1054847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48622</th>\n",
       "      <td>chr11</td>\n",
       "      <td>4940287</td>\n",
       "      <td>5212591</td>\n",
       "      <td>esv2760169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48696</th>\n",
       "      <td>chr11</td>\n",
       "      <td>5004969</td>\n",
       "      <td>5193183</td>\n",
       "      <td>nsv553219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48709</th>\n",
       "      <td>chr11</td>\n",
       "      <td>5081245</td>\n",
       "      <td>5227774</td>\n",
       "      <td>esv3891917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48730</th>\n",
       "      <td>chr11</td>\n",
       "      <td>5117502</td>\n",
       "      <td>5186159</td>\n",
       "      <td>nsv553224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48732</th>\n",
       "      <td>chr11</td>\n",
       "      <td>5144422</td>\n",
       "      <td>5175233</td>\n",
       "      <td>esv3625208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48733</th>\n",
       "      <td>chr11</td>\n",
       "      <td>5154246</td>\n",
       "      <td>5248100</td>\n",
       "      <td>dgv1041n100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2            3\n",
       "48554  chr11  4621644  5179426   nsv1054847\n",
       "48622  chr11  4940287  5212591   esv2760169\n",
       "48696  chr11  5004969  5193183    nsv553219\n",
       "48709  chr11  5081245  5227774   esv3891917\n",
       "48730  chr11  5117502  5186159    nsv553224\n",
       "48732  chr11  5144422  5175233   esv3625208\n",
       "48733  chr11  5154246  5248100  dgv1041n100"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df0[(df0[0]==x19.chr)&(df0[1]<=x)&(df0[2]>=x)]#.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### DGVCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = 'input/features/hg19/DGVCount/DGVCount.all.bed.gz.dgv'\n",
    "\n",
    "df2 = pd.read_csv(file,sep = '\\t', compression='gzip',header = None)\n",
    "df2 = df2[~df2[0].str.contains('chrchr',na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181259</th>\n",
       "      <td>chr5</td>\n",
       "      <td>18907625</td>\n",
       "      <td>26650724</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>inversion</td>\n",
       "      <td>nsv7369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181551</th>\n",
       "      <td>chr5</td>\n",
       "      <td>21523226</td>\n",
       "      <td>29424617</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>inversion</td>\n",
       "      <td>esv3380329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181648</th>\n",
       "      <td>chr5</td>\n",
       "      <td>22419598</td>\n",
       "      <td>24131279</td>\n",
       "      <td>CNV</td>\n",
       "      <td>gain</td>\n",
       "      <td>esv2762506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181710</th>\n",
       "      <td>chr5</td>\n",
       "      <td>23449711</td>\n",
       "      <td>23484372</td>\n",
       "      <td>CNV</td>\n",
       "      <td>gain</td>\n",
       "      <td>nsv597543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2      3          4           5\n",
       "181259  chr5  18907625  26650724  OTHER  inversion     nsv7369\n",
       "181551  chr5  21523226  29424617  OTHER  inversion  esv3380329\n",
       "181648  chr5  22419598  24131279    CNV       gain  esv2762506\n",
       "181710  chr5  23449711  23484372    CNV       gain   nsv597543"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[(df2[0]==x19.chr)&(df2[1].astype(int)<=x)&(df2[2].astype(int)>=x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>chr11</td>\n",
       "      <td>5159347</td>\n",
       "      <td>5167596</td>\n",
       "      <td>7</td>\n",
       "      <td>nsv1054847, esv2760169, nsv553219, esv3891917,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2  3  \\\n",
       "3329  chr11  5159347  5167596  7   \n",
       "\n",
       "                                                      4  \n",
       "3329  nsv1054847, esv2760169, nsv553219, esv3891917,...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alle[(alle[0]==x19.chr)&(alle[1]<=x)&(alle[2]>=x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32828</th>\n",
       "      <td>chr11</td>\n",
       "      <td>4961517</td>\n",
       "      <td>5233820</td>\n",
       "      <td>esv2760169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32873</th>\n",
       "      <td>chr11</td>\n",
       "      <td>5026199</td>\n",
       "      <td>5214412</td>\n",
       "      <td>nsv553219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32896</th>\n",
       "      <td>chr11</td>\n",
       "      <td>5138732</td>\n",
       "      <td>5207388</td>\n",
       "      <td>nsv553224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2           3\n",
       "32828  chr11  4961517  5233820  esv2760169\n",
       "32873  chr11  5026199  5214412   nsv553219\n",
       "32896  chr11  5138732  5207388   nsv553224"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[(df2[0]==x19.chr)&(df2[1]<=x)&(df2[2]>=x)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Filter for pathogenic changes the number for ISCAPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# these are the original files, must filter for pathogenic\n",
    "#files = ['nstd75.GRCh38.variant_call.tsv.gz','nstd45.GRCh38.variant_call.tsv.gz','nstd37.GRCh38.variant_call.tsv.gz']\n",
    "files = ['nstd75.GRCh37.variant_call.tsv.gz','nstd45.GRCh37.variant_call.tsv.gz','nstd37.GRCh37.variant_call.tsv.gz']\n",
    "\n",
    "cols = ['chr','inner_start','inner_stop','#variant_call_accession']\n",
    "\n",
    "alle = pd.DataFrame(columns = cols)\n",
    "st = 'Pathogenic|pathogenic'\n",
    "#st = 'Pathogenic'\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    df = pd.read_csv('delete/'+file,compression='gzip',sep = '\\t', skiprows =1)\n",
    "    df = df[~df['clinical_significance'].str.contains(st,na = False)]\n",
    "    df = df[~df['description'].str.contains(st ,na = False)]\n",
    "    #for col in df.columns:\n",
    "    #    print(df[col].astype(str).str.contains('Pathogenic|pathogenic',na = False).sum())\n",
    "    df = df[~df.chr.isna()]\n",
    "    print(df.shape)\n",
    "    alle = alle.append(df)\n",
    "alle = alle.sort_values(cols)\n",
    "alle = alle[cols].reset_index(drop = True)\n",
    "alle.columns = [0,1,2,3]\n",
    "alle[0]='chr'+alle[0].astype(str)\n",
    "alle[1]=alle[1].astype(int)-1\n",
    "alle[2]=alle[2].astype(int)\n",
    "\n",
    "\n",
    "# when filtered für both pathogenic and pathogeniP 'alle' equals 'df0'\n",
    "#(df0==alle).sum()\n",
    "alle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alle[(alle[0]==x19.chr)&(alle[1]<=x)&(alle[2]>=x)]#.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = ['nstd75.GRCh37.variant_call.tsv.gz','nstd45.GRCh37.variant_call.tsv.gz','nstd37.GRCh37.variant_call.tsv.gz']\n",
    "files = ['nstd45.GRCh37.variant_call.tsv.gz','nstd37.GRCh37.variant_call.tsv.gz']\n",
    "\n",
    "x = 101118632\n",
    "st = 'pathogenic'\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    alle = pd.read_csv('delete/'+file,compression='gzip',sep = '\\t', skiprows =1)\n",
    "    alle.to_csv('delete/test_'+file,compression='gzip',sep = ',',index = None)\n",
    "    alle = alle.sort_values(cols)\n",
    "    alle = alle[~alle.chr.isna()]\n",
    "    alle = alle[~alle['clinical_significance'].str.contains(st,na = False)]\n",
    "    alle = alle[~alle['description'].str.contains(st ,na = False)]\n",
    "\n",
    "    #display(alle.head())\n",
    "    alle = alle[cols].reset_index(drop = True)\n",
    "    alle.columns = [0,1,2,3]\n",
    "    \n",
    "    alle[0]='chr'+alle[0].astype(str)\n",
    "    alle[1]=alle[1].astype(int)-1\n",
    "    alle[2]=alle[2].astype(int)\n",
    "    \n",
    "    display(alle[(alle[0]==x19.chr)&(alle[1]<=x)&(alle[2]>=x)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alle.head(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "regions = [{'hg19':['chr5',23464354,23570942],'hg38':['chr5',23464245,23570833]},\n",
    "                    {'hg19':['chr11',5167199,5327798],'hg38':['chr11',5145969,5306568]},\n",
    "                    {'hg19':['chr14',101118632,101242576],'hg38':['chr14',100652295,100776239]},\n",
    "                   {'hg19':['chr14',101118632,201242576],'hg38':['chr14',100652295,200776239]}]\n",
    "a = 23464354\n",
    "b = 23570942\n",
    "df[(df[0]=='chr5')&(df[1]>=a)&(df[2]<=b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# these are the original files, must filter for pathogenic\n",
    "#files = ['nstd75.GRCh38.variant_call.tsv.gz','nstd45.GRCh38.variant_call.tsv.gz','nstd37.GRCh38.variant_call.tsv.gz']\n",
    "files = ['all_variants_for_nstd75.csv.gz','all_variants_for_nstd37.csv.gz','all_variants_for_nstd45.csv.gz']\n",
    "\n",
    "cols = ['Chromosome','Inner Start','Inner End','Variant ID']\n",
    "\n",
    "alle = pd.DataFrame(columns = cols)\n",
    "st = 'Pathogenic|pathogenic'\n",
    "#st = 'Pathogenic'\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    df = pd.read_csv('hg19.variants/isca/'+file,compression='gzip',sep = ',')\n",
    "\n",
    "    df = df[df['Assembly Name']=='GRCh38 (hg38)'][cols]\n",
    "    print(df.shape)\n",
    "    alle = alle.append(df)\n",
    "alle = alle.sort_values(cols)\n",
    "alle = alle[cols].reset_index(drop = True)\n",
    "alle.columns = [0,1,2,3]\n",
    "alle[0]='chr'+alle[0].astype(str)\n",
    "alle[1]=alle[1].astype(int)-1\n",
    "alle[2]=alle[2].astype(int)\n",
    "\n",
    "\n",
    "alle.to_csv('input/features/hg38/ISCApath/ISCApath.nstd37_nstd45_nstd75.bed.gz.vartmp',sep = '\\t', index = False,header = False,compression = 'gzip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/features/hg38/ISCApath/ISCApath.nstd37_nstd45_nstd75.bed.gz.vartmp',sep = '\\t',compression = 'gzip')\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "regions = [{'hg19':['chr5',23464354,23570942],'hg38':['chr5',23464245,23570833]},\n",
    "                {'hg19':['chr11',5167199,5327798],'hg38':['chr11',5145969,5306568]},\n",
    "                {'hg19':['chr14',101118632,101242576],'hg38':['chr14',100652295,100776239]}]\n",
    "di = regions[2]\n",
    "\n",
    "for d in ['hg19','hg38']:\n",
    "    start = di[d][1]\n",
    "    end = di[d][2]+1\n",
    "    df = pd.DataFrame(index =range(start,end))\n",
    "    df['#CHROM'] = di[d][0]\n",
    "    df['POS'] =  range(start,end)\n",
    "\n",
    "    df[['ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']]=[\".\",\"T\",\"A\",\".\",\"PASS\",\".\"]\n",
    "    df = df.T.reset_index().T\n",
    "    df.columns = ['##fileformat=VCFv4.1']+ ['']*(df.shape[1]-1)\n",
    "    name = di[d][0]+'.'+'pos'+d[2:]\n",
    "    \n",
    "    #df = df.iloc[:90000]\n",
    "    df.to_csv('validation/'+name+'.vcf',header = True,index = False, sep = '\\t')\n",
    "# bgzip 'validation/'+name+'.vcf'\n",
    "# tabix 'validation/'+name+'.vcf'\n",
    "# sbatch_drmaa_snakemake -c cluster.yml -f 'validation/'+name+'.vcf' -j20\n",
    "#shell('bgzip validation/'+name+'.vcf; tabix validation/'+name+'.vcf;')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "for i in list(range(1,23))+['X','Y'][:2]:\n",
    "    gerp = pd.read_csv('input/features/hg19/GerpRS/hg19_chr'+str(i)+'_elems.txt', sep='\\t', header = None)\n",
    "    gerp[5]='chr'+str(i)\n",
    "    df_all = df_all.append(gerp[[5,0,1,3,4]])\n",
    "df_all.to_csv('input/features/hg19/GerpRS/GerpRS.all.bed.gz', sep = '\\t',index = False,header=False,compression='gzip')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = x38.start\n",
    "end = start+10\n",
    "\n",
    "file = 'input/features/hg38/verPhyloP/chr11.phyloP100way.bw'\n",
    "\n",
    "bb = bw.open(file)\n",
    "v = bb.values('chr11', di['hg38'][1],di['hg38'][2]) \n",
    "file = 'input/features/hg38/verPhyloP/chr11_phyloP100way.bw'\n",
    "bb = bw.open(file)\n",
    "v_ = bb.values('chr11', di['hg38'][1],di['hg38'][2]) \n",
    "\n",
    "def interval(df,start,end):\n",
    "    return df[(df.POSITION>=start)&(df.POSITION<end)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Conversation hg19:df19=1\n",
    "# hg38 (df38) korreliert schlecht mit cadd38. Welche Daten nutzt cadd? für 19 ist die Korr 1\n",
    "# Unstimmigkeit Encode VCF unf Originaldateien, hg38\n",
    "# chr5:23464425-23464435\n",
    "l = glob('input/features/hg38/EncH3K4Me3/*.bigWig')\n",
    "for file in l:\n",
    "\n",
    "    bb = bw.open(file)\n",
    "    print(file)\n",
    "    v = bb.values('chr5', 23464425,23464435) \n",
    "    print(v)\n",
    "df38[hg38['EncH3K4Me3']!=df38['EncH3K4Me3']]#.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df38['POSITION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hg38[hg38['EncH3K4Me3']!=df38['EncH3K4Me3']]#.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TEST PRIFASTCONS\n",
    "\n",
    "hg38[hg38['priPhastCons']!=df38['priPhastCons']].head(10)#['EncH3K4Me3']\n",
    "df38[hg38['priPhastCons']!=df38['priPhastCons']].head(10)#['EncH3K4Me3']\n",
    "\n",
    "file = 'input/features/hg38/priPhastCons/hg38_phastCons17way.bw'\n",
    "bb = bw.open(file)\n",
    "v = bb.values('chr5', 23464245,23464255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
