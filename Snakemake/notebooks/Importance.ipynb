{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "os.chdir('/fast/work/groups/ag_kircher/ReMM/MA_Lusi/Snakemake')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "!conda install -c conda-forge jupyter_contrib_nbextensions\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable codefolding/main\n",
    "\n",
    "!conda install -c conda-forge lo\n",
    "!jupyter nbextensions_configurator enable --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "tags": [
     "#1"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "\n",
    "os.chdir('/fast/work/groups/ag_kircher/ReMM/MA_Lusi/Snakemake')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "#2",
     "=>1"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "#3",
     "=>2"
    ]
   },
   "outputs": [],
   "source": [
    "os.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hesdfsdng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kljfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data prearation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "df19 = pd.read_csv('output/features/annotated/hg19/SNVs.hg19.combined.txt.gz', sep = '\\t',header = None)\n",
    "df38 = pd.read_csv('output/features/annotated/hg38/SNVs.hg38.combined.txt.gz', sep = '\\t',header = None)\n",
    "lift= pd.read_csv('output/predictions/lifted/new/hg38.predictions.lifted.txt', sep = '\\t',header = None)\n",
    "\n",
    "\n",
    "df38.index= df38[1].astype(str)+'-'+(df38[2]).astype(str)\n",
    "df19.index= df19[1].astype(str)+'-'+(df19[2]).astype(str)\n",
    "#print(df19.memory_usage().sum()/a,df38.memory_usage().sum()/a,lift.memory_usage().sum()/a)\n",
    "\n",
    "col = pd.read_csv('input/variants/hg38/SNVs.hg38.positive.annotated.tsv.gz', sep = '\\t')\n",
    "#df38 = df38.drop(columns = [0])\n",
    "df38.columns  = ['Score']+col.columns.str.strip().to_list()\n",
    "df38['ID']=list(range(0,len(df38)))\n",
    "\n",
    "col = pd.read_csv('input/variants/hg19/SNVs.hg19.positive.annotated.tsv.gz', sep = '\\t')\n",
    "#df19 = df19.drop(columns = [0])\n",
    "\n",
    "df19.columns  = ['Score']+col.columns.str.strip().to_list()\n",
    "\n",
    "df19.columns = df19.columns.str.replace('46way','')\n",
    "df19.columns = df19.columns.str.replace('fantom','Fantom')\n",
    "\n",
    "df38 = df38.fillna(0)\n",
    "df19 = df19.fillna(0)\n",
    "\n",
    "p = lift[2].str.split(':', expand = True)[1].astype(int)\n",
    "lift.index = lift[2].str.split(':', expand = True)[0]+'-'+p.astype(str)\n",
    "\n",
    "f = df38.join(lift,lsuffix='_38',rsuffix='_lift',how='inner')\n",
    "f.index= f[0].astype(str)+'-'+(f[1]).astype(str)\n",
    "\n",
    "ff = f.join(df19,lsuffix='_38',rsuffix='_19',how='inner')\n",
    "\n",
    "\n",
    "fd = ff.drop_duplicates('ID')\n",
    "fd = fd.drop(columns = ['CHR_19', 'POSITION_19','CHR_38', 'POSITION_38',0,1,2])\n",
    "\n",
    "#fd.to_csv('output/predictions/lifted/new/ff.dataframe.txt',sep = '\\t',index = True,header = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# without normalization \n",
    "#f = fd\n",
    "#col = pd.read_csv('input/variants/hg38/SNVs.hg38.positive.annotated.tsv.gz', sep = '\\t')\n",
    "#cols = col.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = pd.read_csv('/data/groups/ag_kircher/ReMM/MA_Lusi/SingleFeatureImpact/cleaned_scaled_combined_annotations.tsv.gz',sep='\\t')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-38f19750c129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fd' is not defined"
     ]
    }
   ],
   "source": [
    "# normalize and save the data \n",
    "from sklearn import preprocessing\n",
    "\n",
    "cols = fd.columns\n",
    "\n",
    "f = preprocessing.normalize(fd,axis = 0)\n",
    "f = pd.DataFrame(f)\n",
    "f.columns = cols\n",
    "\n",
    "f['Score_38'] =fd.reset_index()['Score_38']\n",
    "f['Score_19'] =fd.reset_index()['Score_19']\n",
    "\n",
    "\n",
    "col = pd.read_csv('input/variants/hg38/SNVs.hg38.positive.annotated.tsv.gz', sep = '\\t')\n",
    "cols = col.columns[3:]\n",
    "cols\n",
    "#f.to_csv('output/predictions/lifted/new/ff.dataframe.normiert.txt',sep = '\\t',index = True,header = True),float_format='%.5f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(fd['GCContent_38'] - fd['GCContent_38'].mean())/fd['GCContent_38'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f0['GCContent_38']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f1['GCContent_38']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Read in normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df19 = f.iloc[:,f.columns.str.contains('_19',na = False)]\n",
    "df19.columns = df19.columns.str.replace('_19','')\n",
    "df38 = f.iloc[:,f.columns.str.contains('_38',na = False)]\n",
    "df38.columns = df38.columns.str.replace('_38','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df19.corrwith(df38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f=pd.read_csv('output/predictions/lifted/new/ff.dataframe.normiert.txt',sep = '\\t',index_col = 'Unnamed: 0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "col = pd.read_csv('input/variants/hg38/SNVs.hg38.positive.annotated.tsv.gz', sep = '\\t')\n",
    "cols = col.columns[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f['GerpRSpv_19'].value_counts() # normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f['GerpRS_19'].value_counts() # normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ff['GerpRSpv_19'].value_counts() # not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ff['GerpRS_19'].value_counts() # not normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Devide the dataset into positive and negative dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['Label_19']=f['Label_38']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = f.reset_index(drop =True)\n",
    "p = f[f['Label_38']==1]\n",
    "n = f[f['Label_38']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T14:57:10.395174Z",
     "start_time": "2021-03-05T14:57:10.375575Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.loc[:,'Fantom5Robust_19'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = f.apply(lambda x: x.round(6))\n",
    "#f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run linear and logistic regressoins, calculate correlations and means of feature values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     15,
     47,
     74
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial import distance\n",
    "import random\n",
    "\n",
    "# dataframes to append lists with importance and correaltions\n",
    "# each column is a list from one run (in total 100 for each genome build)\n",
    "logistic = pd.DataFrame()\n",
    "distances = pd.DataFrame()\n",
    "linear = pd.DataFrame()\n",
    "correlations = pd.DataFrame()\n",
    "\n",
    "means_pos = pd.DataFrame()\n",
    "means_neg = pd.DataFrame()\n",
    "\n",
    "for i in range (0,100):\n",
    "    # sample 406 random data points from the negative set\n",
    "    s = random.sample(range(0, len(f)),406)\n",
    "    df = n[n.index.isin(s)]\n",
    "    # append the positive dataset\n",
    "    df = df.append(p)\n",
    "    \n",
    "    # list of dataframes with 802 data points to calculate the euclidean distance \n",
    "    frames = []\n",
    "    \n",
    "    for a in ['_19','_38']:\n",
    "        \n",
    "        # lists to append importance and correlation values vor each iteration\n",
    "        linear_list = []\n",
    "        logistic_list = []\n",
    "        correlations_list = []\n",
    "        distances_list = []\n",
    "        # filter for hg19 or hg38\n",
    "        df_a = df.iloc[:,df.columns.str.contains(a,na = False)]\n",
    "        df_a.columns = df_a.columns.str.replace(a,'')\n",
    "\n",
    "        # devide into positive and negatove for feature means\n",
    "        df_a_pos = df_a.loc[df_a['Label']==1,cols]\n",
    "        df_a_neg = df_a.loc[df_a['Label']==0,cols]\n",
    "        \n",
    "        \n",
    "        # calculate feature means \n",
    "        means_pos[str(i)+a] = df_a_pos.mean(axis = 0)\n",
    "        means_neg[str(i)+a] = df_a_neg.mean(axis = 0)\n",
    "\n",
    "        frames.append(df_a)\n",
    "        \n",
    "        for column in cols:\n",
    "            # choose the column for the univariate analysis \n",
    "            X = df_a.loc[:,column].to_numpy().reshape(-1, 1)\n",
    "            y = df_a['Label']\n",
    "            \n",
    "            # calculate the linear model\n",
    "            model = LinearRegression().fit(X, y)\n",
    "            importance = model.coef_[0]\n",
    "            linear_list.append(importance)\n",
    "            \n",
    "            # calculate the logistic model\n",
    "            model = LogisticRegression().fit(X, y)\n",
    "            importance = model.coef_[0]\n",
    "            logistic_list.append(importance[0])\n",
    "            \n",
    "            # calculate the correlation between scores (y) and feature (X)\n",
    "            # c is a df with two columns, df.corr() returns a correlation matrix\n",
    "            c = pd.DataFrame([list(X.flatten()),y]).T.corr().iloc[1,0]\n",
    "            correlations_list.append(c)\n",
    "            \n",
    "           \n",
    "        # lists are columns of final dataframes\n",
    "        linear[str(i)+a] = linear_list\n",
    "        logistic[str(i)+a] = logistic_list\n",
    "        correlations[str(i)+a] = correlations_list\n",
    "        \n",
    "    # calculate euclidean distance     \n",
    "    for column in cols: \n",
    "        dist = distance.euclidean(frames[0].loc[:,column], frames[1].loc[:,column])\n",
    "        distances_list.append(dist)\n",
    "\n",
    "    distances[str(i)+a] = distances_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def kop(tog,name):        \n",
    "    # input: dataframe with results of the loop (see example above)\n",
    "    # output: a dataframe with two columns (hg19 and hg38) with means from the runs\n",
    "    \n",
    "    \n",
    "    a = tog.loc[:,tog.columns.str.contains('_19')].mean(axis = 1)\n",
    "    b = tog.loc[:,tog.columns.str.contains('_38')].mean(axis = 1)\n",
    "\n",
    "    alle = pd.DataFrame([a,b]).T\n",
    "    alle['index'] = cols#.append(cols)\n",
    "    alle = alle.set_index('index')\n",
    "\n",
    "    alle.index.name=''\n",
    "    alle.columns = ['ReMM '+name,'parSMURF '+name]\n",
    "    return  alle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kop(correlations, 'Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# join all the means in one table\n",
    "al = kop(linear,'Linear').join(kop(logistic,'Logistic')).join(kop(means_pos, 'Positive Mean'))\n",
    "al = al.join(kop(means_neg, 'Negative Mean')).join(kop(correlations, 'Correlation'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add euclidean distance\n",
    "d = distances.mean(axis = 1)\n",
    "d.name = 'Euclidean Distance'\n",
    "d.index = cols\n",
    "al= al.join(d)\n",
    "\n",
    "al['Euclidean Distance'] = al['Euclidean Distance'].astype(float).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.read_csv('input/variants/hg38/SNVs.hg38.positive.annotated.tsv.gz', sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parSMURF Tree means\n",
    "col = pd.read_csv('input/variants/hg38/SNVs.hg38.positive.annotated.tsv.gz', sep = '\\t')\n",
    "\n",
    "\n",
    "imp = pd.DataFrame()\n",
    "for i in range(99):\n",
    "    df = pd.read_csv('models/hg38/'+str(i)+'.out.importance',sep = ' ',header = None)\n",
    "    imp[i]=df[1]\n",
    "\n",
    "imp.index = col.columns[3:]\n",
    "imp = imp.mean(axis = 1)\n",
    "imp = pd.DataFrame(imp)\n",
    "\n",
    "\n",
    "imp.columns = ['ParSMURF Tree']\n",
    "df_order = pd.DataFrame(imp).join(al)\n",
    "\n",
    "df_order.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# order of values: order descending, add a columns with list from 1 to 26\n",
    "for c in df_order.columns:\n",
    "    df_order = df_order.sort_values(by=[c], ascending = False)\n",
    "    df_order[c+' Order'] = list(range(1,27))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_order.iloc[:,-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# df_order[['ReMM Linear Order','ReMM Correlation Order','parSMURF Linear Order','parSMURF Correlation Order']].sort_values(by=['parSMURF Linear Order'], ascending = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('output/predictions/hg19/remm_with_ps_predictions.csv',sep ='\\t',compression = 'gzip',header = None)\n",
    "var = pd.read_csv('output/features/annotated/hg19/SNVs.hg19.combined.txt.gz',sep = '\\t', compression = 'gzip',header = None, usecols = [0,1,2])\n",
    "ps = pd.read_csv('output/predictions/hg19/SNVs.hg19.predictions.txt', sep = '\\t',header = None)\n",
    "\n",
    "var['prediction']=ps[0]\n",
    "df['id']=df[0]+'-'+df[1].astype(str)\n",
    "var['id']=var[1]+'-'+var[2].astype(str)\n",
    "var = var.set_index('id')\n",
    "df = df.set_index('id')\n",
    "\n",
    "fc = var.join(df, how='inner',lsuffix = 'ps',rsuffix='remm')\n",
    "\n",
    "fc[['prediction','2remm']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "df = fc.reset_index()\n",
    "a = []\n",
    "for i in range(10):\n",
    "    s = random.sample(range(0, len(fc)),100000)\n",
    "    df0 = df[df.index.isin(s)]\n",
    "    print(df0.shape)\n",
    "    a.append(df0[['prediction','2remm']].corr().iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallo0\n"
     ]
    }
   ],
   "source": [
    "print('Hallo0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getImportance(hg): \n",
    "    file  = 'input/variants/'+hg+'/SNVs.'+hg+'.positive.annotated.tsv.gz'\n",
    "    #print(file)\n",
    "    col = pd.read_csv(file, sep = '\\t')\n",
    "\n",
    "\n",
    "    imp = pd.DataFrame()\n",
    "    for i in range(99):\n",
    "        df = pd.read_csv('models/'+hg+'/'+str(i)+'.out.importance',sep = ' ',header = None)\n",
    "        imp[i]=df[1]\n",
    "\n",
    "    c=3\n",
    "    if hg=='hg19':\n",
    "        c = 2\n",
    "        col.columns = col.columns.str.replace('46way','').str.replace('fantom','Fantom')\n",
    "    \n",
    "    imp.index = col.columns[c:]\n",
    "    imp = imp.mean(axis = 1)\n",
    "    imp = pd.DataFrame(imp)\n",
    "    imp.columns = ['ParSMURF Tree']\n",
    "    return imp.round(5)\n",
    "\n",
    "\n",
    "df_order = getImportance('hg38').join(getImportance('hg19'),lsuffix = '_hg38',rsuffix = '_hg19')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for a in ['_19','_38']:\n",
    "    df_a = f.iloc[:,f.columns.str.contains(a,na = False)]\n",
    "    df_a.columns = df_a.columns.str.replace(a,'')\n",
    "    dfs.append(df_a)\n",
    "a = dfs[0].corrwith(dfs[1])\n",
    "a = pd.DataFrame(a)\n",
    "a.columns = ['Correlation']\n",
    "df_order = df_order.join(a,how ='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_order.columns:\n",
    "    df_order = df_order.sort_values(by=[c], ascending = False)\n",
    "    df_order[c+' Order'] = list(range(1,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df_order[['ParSMURF Tree_hg38','ParSMURF Tree_hg19']].max().min()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.sort_values(by=['ParSMURF Tree_hg38'], ascending = False).to_latex('figures/importance.latex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2\n",
    "\n",
    "\n",
    "feature = 'ParSMURF Tree_hg38'\n",
    "features = ['ParSMURF Tree_hg19','ParSMURF Tree_hg38']\n",
    "\n",
    "for feature in features:\n",
    "    a = df_order.sort_values(by=[feature], ascending = True)\n",
    "\n",
    "    #a['group'] = a['group'].map(colors)\n",
    "\n",
    "    #colors = {0:'teal',1:'lightblue',2:'steelblue',3:'lightsteelblue'}\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "\n",
    "    ax.barh(a.index, a.loc[:,feature],color = a.loc[:,'color'])\n",
    "    ax.set_xlabel('Importance', fontsize = 10*x,labelpad=15)\n",
    "    #ax.set_ylabel('Feture',fontsize = 10*x,labelpad=10)\n",
    "    ax.tick_params(axis='both',  labelsize=8*x)\n",
    "    #ax.set_xlim([0, 0.5])\n",
    "    #ax.set_xbound(lower=0.0, upper=m)\n",
    "    ax.autoscale(enable=True, axis='y')\n",
    "    plt.legend(*zip(*[(plt.Rectangle((0,0), 1,1, color=c), f\"{i}\") for i,c in colors.items()]),fontsize = 9*x,loc = 4) \n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('figures/'+feature+'_bar.png',di=30,bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order['group'] ='Epigenetic profile'\n",
    "ind = df_order.index[df_order.index.str.contains('GC|CpG')].to_list()\n",
    "df_order.loc[ind,'group']='GC-based'\n",
    "ind = df_order.index[df_order.index.str.contains('PhastCons|PhyloP|Gerp')].to_list()\n",
    "df_order.loc[ind,'group']='Conservation and constraint'\n",
    "ind = df_order.index[df_order.index.str.contains('Var|VAR|ISCApath|fracRareCommon|dbVARCount|DGVCount')].to_list()\n",
    "df_order.loc[ind,'group']='Genetic variation'\n",
    "colors = {'Epigenetic profile':'teal','GC-based':'lightblue','Conservation and constraint':'steelblue','Genetic variation':'lightsteelblue'}\n",
    "#a = df_order.sort_values(by=[feature], ascending = True)\n",
    "\n",
    "df_order['color'] = df_order['group'].map(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'Epigenetic profile':'teal','GC-based':'lightblue','Conservation and constraint':'steelblue','Genetic variation':'lightsteelblue'}\n",
    "#colors = {'teal':0,'lightblue':1,'steelblue':2,'lightsteelblue':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_order.sort_values(by=[feature], ascending = True)\n",
    "\n",
    "a['color'] = a['group'].map(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a#.loc[:,'color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature = 'ParSMURF Tree_hg19'\n",
    "a = df_order.sort_values(by=[feature], ascending = False)\n",
    "a = a.loc[:,feature]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "notebooks/Importance.ipynb",
    "public": false
   },
   "id": ""
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "321px",
    "left": "973px",
    "right": "20px",
    "top": "120px",
    "width": "374px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
